{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 28.01.2022\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 14.02.2022\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 17.02.2022\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LasEofiLFmPs",
    "outputId": "fe34c244-8b78-421a-d1d7-1d445b7cf149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x7F8F88066950"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng(2022)\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "#__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDwRbdxTrSAu"
   },
   "source": [
    "### Тесты без пайплайна (не надо проверять)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rM2t4FwuN6dZ",
    "outputId": "2f1e2187-fda1-4ad0-9d40-0a725b3c1159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54397.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi = x_train[np.random.randint(x_train.shape[0], size=1000000)]\n",
    "xj = x_train[np.random.randint(x_train.shape[0], size=1000000)]\n",
    "\n",
    "sigma_male = np.median(np.sum((xi - xj)**2, axis=1))\n",
    "sigma_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvibIIbx20To"
   },
   "outputs": [],
   "source": [
    "###DO NOT SCALE \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# x_train = scaler.fit_transform(x_train)\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5qrSU5olZUh"
   },
   "outputs": [],
   "source": [
    "w_samples = np.random.normal(0, 1/sigma_male, (100, x_train.shape[1]))\n",
    "b = np.random.uniform(-np.pi, np.pi, 100)\n",
    "\n",
    "phi_x_train = np.cos(x_train @ w_samples.T + b)\n",
    "phi_x_test = np.cos(x_test @ w_samples.T + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtCsoRIWtU1y",
    "outputId": "15dec804-07b8-44d0-a78c-93451c6893a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfKcfmDDB5Nz"
   },
   "source": [
    "**Без PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1kfebtEhWsR",
    "outputId": "1bb581a9-6be8-43dc-94ac-47a44cb2160f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7421"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "svc = SVC(kernel='linear', probability=True)\n",
    "svc.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "y1_pred = svc.predict(phi_x_test)\n",
    "(y1_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIf4MSuZmjLf",
    "outputId": "e54f4005-8339-4a76-d933-40d5081e7369"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "lin_svc = LinearSVC(max_iter=3000)\n",
    "lin_svc.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "y2_pred = lin_svc.predict(phi_x_test)\n",
    "(y2_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EFjQ-xRmFM5",
    "outputId": "6aaaa3b0-9894-44fd-b860-32ab10476bba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7263"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='saga', max_iter=1000)\n",
    "logreg.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "y3_pred = logreg.predict(phi_x_test)\n",
    "(y3_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyDlsahB7rgu",
    "outputId": "f3eef38c-21b8-4a9d-efce-bed8317b9314"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7261"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='saga', max_iter=100)\n",
    "logreg.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "y3_pred = logreg.predict(phi_x_test)\n",
    "(y3_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBYDgZM-CJZ6"
   },
   "source": [
    "**Используя PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnMbFz06qRzB"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca_train = pca.fit_transform(x_train)\n",
    "pca_test = pca.transform(x_test)\n",
    "\n",
    "w_samples = np.random.normal(0, 1/sigma_male, (100, pca_train.shape[1]))\n",
    "b = np.random.uniform(-np.pi, np.pi, 100)\n",
    "\n",
    "phi_x_train = np.cos(pca_train @ w_samples.T + b)\n",
    "phi_x_test = np.cos(pca_test @ w_samples.T + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cswsosneq7th",
    "outputId": "db5e51e7-a411-45a6-c34a-b5ac9421c9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7458"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "svc = SVC(kernel='linear', probability=True)\n",
    "svc.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "ysample_pred = svc.predict(phi_x_test)\n",
    "(ysample_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odoH4_mdq_bD",
    "outputId": "65a7e9c3-add5-4d47-ec04-6f0fbbe8800c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "lin_svc = LinearSVC(max_iter=3000)\n",
    "lin_svc.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "ysample_pred = lin_svc.predict(phi_x_test)\n",
    "(ysample_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVaW1gOuq-nK",
    "outputId": "a31d3092-3da7-44bb-9ca9-a3a1d9470880"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7316"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='saga', max_iter=1000)\n",
    "logreg.fit(phi_x_train[:5000], y_train[:5000])\n",
    "\n",
    "ysample_pred = logreg.predict(phi_x_test)\n",
    "(ysample_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoGHHUfYreG7"
   },
   "source": [
    "### Финальная модель с пайплайном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, use_scaler=False, classifier='logreg'):\n",
    "        \"\"\"\n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "          n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "          new_dim, int: PCA output size.\n",
    "          use_PCA, bool: whether to include PCA preprocessing.\n",
    "          classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.use_scaler = use_scaler\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Sigma squared Male Rule estimation\n",
    "        mask = np.random.randint(X.shape[0], size=(2, 1000000))\n",
    "        xi, xj = X[mask[0]], X[mask[1]]\n",
    "        sigma_sq = np.median(np.sum(((xi - xj) ** 2), axis=1))\n",
    "        \n",
    "        # Scaling and PCA\n",
    "        # scaler = StandardScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "\n",
    "        # Generating features with RFF\n",
    "        self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "        self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "        Phi_X = np.cos(X @ self.w_samples.T + self.b)\n",
    "        \n",
    "        # Scaling new features and fit\n",
    "        if self.use_scaler:\n",
    "            self.scaler = StandardScaler()\n",
    "            Phi_X = self.scaler.fit_transform(Phi_X)\n",
    "            \n",
    "        if self.classifier == 'svm':\n",
    "            self.svc = SVC(kernel='linear', probability=False)\n",
    "            self.svc.fit(Phi_X, y)\n",
    "            \n",
    "        if self.classifier == 'logreg':\n",
    "            self.logreg = LogisticRegression(solver='saga')\n",
    "            self.logreg.fit(Phi_X, y)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Scaling and PCA\n",
    "        # scaler = StandardScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        \n",
    "        # Generating features with RFF\n",
    "        Phi_X = np.cos(X @ self.w_samples.T + self.b)\n",
    "        \n",
    "        # Probabilities\n",
    "        if self.classifier == 'svm':\n",
    "            return self.svc.predict_proba(Phi_X)\n",
    "            \n",
    "        if self.classifier == 'logreg':\n",
    "            return self.logreg.predict_proba(Phi_X)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Scaling and PCA\n",
    "        # scaler = StandardScaler()\n",
    "        # X = scaler.fit_transform(X)\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "            \n",
    "        # Generating features with RFF\n",
    "        Phi_X = np.cos(X @ self.w_samples.T + self.b)\n",
    "        \n",
    "        # Classification\n",
    "        if self.classifier == 'svm':\n",
    "            return self.svc.predict(Phi_X)\n",
    "            \n",
    "        if self.classifier == 'logreg':\n",
    "            return self.logreg.predict(Phi_X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJdtN5T6ZYq0",
    "outputId": "58a06a4b-ecdd-4231-c106-08135fdd5a1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8171"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmtU0ZCJg5IP",
    "outputId": "68ac7f3b-964b-4017-8896-2bdec37d1e3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8039"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc2OukcLC2ig"
   },
   "source": [
    "На подвыборке лучше себя показала модель без PCA. Поэтому для финальной прогонки используем именно её."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpsAnmkwhg2e",
    "outputId": "3866e67c-dd24-47e9-f47e-61f92b4a039b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "model = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier='svm')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyiCU95ORjZS"
   },
   "source": [
    "Обучение на всей выборке заняло 23 минуты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "#__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Mk03D9E3XcpN"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import time\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DefLKfJvZcJx",
    "outputId": "d04f2067-371a-41cc-edb2-2b2754fabfa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM accuracy: 0.7332\n",
      "--- 22.760557413101196 seconds ---\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "start_time = time.time()\n",
    "\n",
    "lin_svc = LinearSVC(max_iter=3000)\n",
    "lin_svc.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = lin_svc.predict(x_test)\n",
    "print(f\"LinearSVM accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADR8jC9RaXFX",
    "outputId": "c19c751e-d01a-4d1d-f778-f291f69c4b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelSVM accuracy: 0.7976\n",
      "--- 13.547722339630127 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "kernel_svc = SVC(kernel='linear')\n",
    "kernel_svc.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = kernel_svc.predict(x_test)\n",
    "print(f\"KernelSVM accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlbIiQxQXOdj",
    "outputId": "af15af81-5adb-41fa-8f8e-0344d8e65b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelSVM accuracy: 0.8343\n",
      "--- 24.421908617019653 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "kernel_svc = SVC(kernel='rbf')\n",
    "kernel_svc.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = kernel_svc.predict(x_test)\n",
    "print(f\"KernelSVM accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKc-4Bq9ZPtZ"
   },
   "source": [
    "Как можно видеть линейный SVM уступает ядровому методу при одинаковом времени обучения. Это как раз связано с тем, что гауссовское ядро, которое используется в ядровом SVM позволяет использовать признаки из бесконечномерного пространства, где они могут быть линейно разделимыми. Тогда как линейный метод использует исходные признаки. \n",
    "\n",
    "Комментарий насчет разницы между LinearSVC() и SVC(kernel='linear'). LinearSVC это более гибкий класс для обучения линейных классификаторов, так как он использует библиотеку liblinear, который позволяет настраивать регуляризацию и лоссы. \n",
    "SVC(kernel='linear') использует библиотекку libsvm, поэтому на больших данных LinearSVC обучается быстрее. \\\\\n",
    "https://stackoverflow.com/questions/11508788/whats-the-difference-between-libsvm-and-liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qN8LUlJgK-hV",
    "outputId": "d337b3ad-dbcb-47bc-e5d2-1bc18c37da6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.8349\n",
      "--- 114.93435788154602 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(f\"XGBoost accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3cKtRInqIaC"
   },
   "source": [
    "Подберем параметры бустинга:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXIDzwS-dwnH",
    "outputId": "5296929c-370c-4661-f3fa-7ef172e8a354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGB accuracy: 0.8009, params: 2, 50\n",
      "--- 40.6189444065094 seconds ---\n",
      "Tuned XGB accuracy: 0.8224, params: 2, 100\n",
      "--- 73.7978003025055 seconds ---\n",
      "Tuned XGB accuracy: 0.8371, params: 2, 200\n",
      "--- 145.689377784729 seconds ---\n",
      "Tuned XGB accuracy: 0.8202, params: 3, 50\n",
      "--- 54.45456504821777 seconds ---\n",
      "Tuned XGB accuracy: 0.8349, params: 3, 100\n",
      "--- 107.29931879043579 seconds ---\n",
      "Tuned XGB accuracy: 0.8463, params: 3, 200\n",
      "--- 222.4045352935791 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for m_depth in [2, 3]:\n",
    "  for n_est in [50,100, 200]:\n",
    "    start_time = time.time()\n",
    "    xgb = XGBClassifier(max_depth=m_depth, n_estimators=n_est)\n",
    "    xgb.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    print(f\"Tuned XGB accuracy: {np.mean(y_pred == y_test)}, params: {m_depth}, {n_est}\")\n",
    "    print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1XlfvLPkDrP"
   },
   "source": [
    "Даже без подбора гиперпараметров XGBoost выдает результат, сопоставимый с результатом ядрового SVM. Однако потраченное на обучение время у бустинга в 4 раза больше, чем у SVM. Если же еще брать в расчет подбор параметров, то бустинг самый долгий, однако за это время качество у модели действительно повысится чуть меньше, чем на процент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wazxXSpbxdk"
   },
   "source": [
    "**Используя PCA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ny7ZqEsbwKA"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pc_train = pca.fit_transform(x_train)\n",
    "pc_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inafburAb2mL",
    "outputId": "111066a9-b023-4eab-bcc5-fa32e2381e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM accuracy: 0.6094\n",
      "--- 30.227136611938477 seconds ---\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "start_time = time.time()\n",
    "\n",
    "lin_svc = LinearSVC(max_iter=3000)\n",
    "lin_svc.fit(pc_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = lin_svc.predict(pc_test)\n",
    "print(f\"LinearSVM accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9rdDhfmb22i",
    "outputId": "3407f768-17d1-49fa-9b55-c5b3424e99a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelSVM accuracy: 0.8747\n",
      "--- 105.41046977043152 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "kernel_svc = SVC(kernel='rbf')\n",
    "kernel_svc.fit(pc_train, y_train)\n",
    "\n",
    "y_pred = kernel_svc.predict(pc_test)\n",
    "print(f\"KernelSVM accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6rm6Ue4b3mg",
    "outputId": "65091265-09e7-4e05-fe43-f11c0703ab18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.8181\n",
      "--- 34.72909140586853 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "xgb = XGBClassifier(max_depth=3, n_estimators=200)\n",
    "xgb.fit(pc_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = xgb.predict(pc_test)\n",
    "print(f\"XGBoost accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP4xtHUGcbU_"
   },
   "source": [
    "Выделение главных компонент существенно ускоряет ядровой SVM, да так, что даже можно обучиться на всем датасете чуть больше, чем за минуту (23 минуты без PCA!). Причем accuracy в таком случае вырастет существенно, аж до 0.87. \\\\\n",
    "XGBoost выдает похожее качсетво, но за большее время, поэтому осмысленно использовать именно ядровой метод, который быстрее. Не исключено, что бустинг на всем датасете при праивльно подобранных параметрах выдаст что-то большее, однако это опять же займет очень много времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "# __Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \\\\\n",
    "Помогает, как мы выяснили в предыдущем пункте, понижение размерности значительно ускоряет PCA, так как признаков становится меньше (50 вместо 784), а информация о данных сохраняется наибольшая (PCA отбирает 50 самых информативных признаков по дисперсии). Отсюда, обучение проходит в несколько раз быстрее, 1.5 минуты против 23 минут без PCA.\n",
    "\n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features? \\\\\n",
    "При росте n_features качество растет и выходит на плато примерно на 1000-1500 признаках. Чем больше признаков, тем больше нелинейных закономерностей улавливает модель, используя ядро, поэтому качество растет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "c2QIHIMbK-hW",
    "outputId": "6536b930-a091-41f9-b7d4-ebac55deb635"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracies = []\n",
    "\n",
    "for n_features in [100, 200, 500, 1000, 2000, 4000]:\n",
    "  model = RFFPipeline(n_features=n_features, new_dim=50, use_PCA=True, classifier='svm')\n",
    "  model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "  y_pred = model.predict(x_test)\n",
    "  accuracies.append(np.mean(y_pred == y_test))\n",
    "\n",
    "plt.plot([100, 200, 500, 1000, 2000, 4000], accuracies)\n",
    "plt.title('Аccuracy dependence on number of features.')\n",
    "plt.xlabel('n features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVukEqhysubf"
   },
   "source": [
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM? \\\\\n",
    "Незначительно, но все же SVM предпочтительнее использовать, чем Logreg для ядерной аппроксимации. SVM показывает лучшее качество и не уступает логрегу по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KCRfjnoMwrL-",
    "outputId": "8b60ed81-7ccc-4319-a3b2-96c5d7f775a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg accuracy: 0.7777\n",
      "--- 33.91533327102661 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='logreg')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Logreg accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgpB2WUcw_cm",
    "outputId": "4428e689-8b6a-414d-9f54-77a54270b796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.8063\n",
      "--- 27.41907238960266 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"SVM accuracy: {np.mean(y_pred == y_test)}\")\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "# __Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "# __Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nhr7LIsNPYQy"
   },
   "source": [
    "Добавим несколько функций для генерации новых признаков в наш класс и поочередно протеситурем их на подвыборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "class CoolerPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=False, func='rff', classifier='logreg'):\n",
    "        \"\"\"\n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "          n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "          new_dim, int: PCA output size.\n",
    "          use_PCA, bool: whether to include PCA preprocessing.\n",
    "          classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        self.func = func\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Sigma squared Male Rule estimation\n",
    "        mask = np.random.randint(X.shape[0], size=(2, 1000000))\n",
    "        xi, xj = X[mask[0]], X[mask[1]]\n",
    "        sigma_sq = np.median(np.sum(((xi - xj) ** 2), axis=1))\n",
    "        \n",
    "        # Scaling and PCA\n",
    "        if self.use_PCA:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "\n",
    "        # Generating features\n",
    "        if self.func == 'rff':\n",
    "          self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = np.cos(X @ self.w_samples.T + self.b)\n",
    "\n",
    "        elif self.func == 'arctan':\n",
    "          self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = np.arctan(X @ self.w_samples.T + self.b)\n",
    "        \n",
    "        elif self.func == 'sinh':\n",
    "          self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = np.sinh(X @ self.w_samples.T + self.b)\n",
    "\n",
    "        elif self.func == 'indic':\n",
    "          self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = (np.cos(X @ self.w_samples.T + self.b) > 0)\n",
    "\n",
    "        elif self.func == 'sigmoid':\n",
    "          self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = 1 / (1 + np.exp(- X @ self.w_samples.T + self.b))\n",
    "        \n",
    "        elif self.func == 'relu':\n",
    "          self.w_samples = np.random.normal(0, 1/sigma_sq, (self.n_features, X.shape[1]))\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = ((X @ self.w_samples.T + self.b) > 0) * (X @ self.w_samples.T + self.b)\n",
    "\n",
    "        elif self.func == 'student':\n",
    "          self.w_samples = np.random.standard_t(df=1, size=(self.n_features, X.shape[1]))/sigma_sq\n",
    "          self.b = np.random.uniform(-np.pi, np.pi, self.n_features)\n",
    "          Phi_X = np.cos(X @ self.w_samples.T + self.b)\n",
    "      \n",
    "        # Fit\n",
    "        if self.classifier == 'svm':\n",
    "            self.svc = SVC(kernel='linear', probability=True)\n",
    "            self.svc.fit(Phi_X, y)\n",
    "            \n",
    "        elif self.classifier == 'logreg':\n",
    "            self.logreg = LogisticRegression(solver='saga')\n",
    "            self.logreg.fit(Phi_X, y)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)  # PCA\n",
    "        \n",
    "        if self.func == 'rff':\n",
    "          Phi_X = np.cos(X @ self.w_samples.T + self.b)  # RFF\n",
    "\n",
    "        elif self.func == 'arctan':\n",
    "          Phi_X = np.arctan(X @ self.w_samples.T + self.b)  # Arctan\n",
    "\n",
    "        elif self.func == 'sinh':\n",
    "          Phi_X = np.sinh(X @ self.w_samples.T + self.b)  # Sinh\n",
    "          \n",
    "        elif self.func == 'indic':\n",
    "          Phi_X = (np.cos(X @ self.w_samples.T + self.b) > 0)  # Indicator\n",
    "        \n",
    "        elif self.func == 'sigmoid':\n",
    "          Phi_X = 1 / (1 + np.exp(- X @ self.w_samples.T + self.b))  # Sigmoid\n",
    "\n",
    "        elif self.func == 'relu':\n",
    "          Phi_X = ((X @ self.w_samples.T + self.b) > 0) * (X @ self.w_samples.T + self.b)  # RELU\n",
    "\n",
    "        if self.func == 'student':\n",
    "          Phi_X = np.cos(X @ self.w_samples.T + self.b)  # Student\n",
    "\n",
    "        if self.classifier == 'svm':\n",
    "            return self.svc.predict(Phi_X)\n",
    "            \n",
    "        if self.classifier == 'logreg':\n",
    "            return self.logreg.predict(Phi_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIll6MvsUIGN",
    "outputId": "80d55268-c949-475e-f6a9-3f5fb43f353c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8143"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "model = CoolerPipeline(n_features=1000, func='rff', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"RFF accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrDre2P_VASZ",
    "outputId": "ce774d0c-5fce-4e72-a7fc-7680a5d81a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arctanh accuracy: 0.8044\n"
     ]
    }
   ],
   "source": [
    "model = CoolerPipeline(n_features=1000, func='arctan', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Arctan accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxEDPIj0VsQu",
    "outputId": "e4bedd51-7a3d-4584-ce45-cc6b2b75ee60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SinH accuracy: 0.8111\n"
     ]
    }
   ],
   "source": [
    "model = CoolerPipeline(n_features=1000, func='sinh', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"SinH accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErY-F7IMVcPI",
    "outputId": "a841c0dc-1937-48d3-f054-41492ffeaa8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator accuracy: 0.6665\n"
     ]
    }
   ],
   "source": [
    "model = CoolerPipeline(n_features=1000, func='indic', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Indicator accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MutWtRty411r",
    "outputId": "3f2934fa-400f-4f34-ebda-8d1b0b81b547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid accuracy: 0.5568\n"
     ]
    }
   ],
   "source": [
    "model = CoolerPipeline(n_features=1000, func='sigmoid', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Sigmoid accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTa4eNDH6qIr",
    "outputId": "a469f737-44f3-4009-99bf-9ad916bdd7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELU accuracy: 0.8165\n"
     ]
    }
   ],
   "source": [
    "model = CoolerPipeline(n_features=1000, func='relu', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"RELU accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9O5LKy2j-ii6",
    "outputId": "9a213d78-b2b1-4114-df94-fec4b1c54c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student accuracy: 0.8033\n"
     ]
    }
   ],
   "source": [
    "model = CoolerPipeline(n_features=1000, func='student', classifier='svm')\n",
    "model.fit(x_train[:5000], y_train[:5000])\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Student accuracy: {np.mean(y_pred == y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYa9INGac82Y"
   },
   "source": [
    "В экспериментах я использовал арктангенс и гиперболический синус, которые показали качество сравнимые с RFF. Связано это наверное с тем, что обе эти функции монотонно возрастают на всех вещественной оси, не превнося какие-то радикальные изменения в признаки. \\\\\n",
    "После этого я попробовал разные функции активации из нейронных сетей, которые могут как-то преобразовать признаки. \\\\\n",
    "https://mlfromscratch.com/activation-functions-explained/#/ \\\\\n",
    "Первой я попробовал step function, то есть индикатор от косинуса, однако качество сильно понизилось до 0.67. \\\\\n",
    "Второй была сигмоида, качество упало еще ниже до 0.56. \\\\\n",
    "И третьей я протестировал RELU, которая выдала такое же качество, что и RFF 0.81.\n",
    "\n",
    "Последним, что я хотел поменять это распределение, из которого сэмплятся веса w. Вместо нормального я использовал t распределение с более тяжелыми хвостами. Качество опять же вышло сопоставимым с обычным RFF.\n",
    "\n",
    "В итоге, ничего лучше RFF придумать не вышло)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vk9luf97Vsq3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAGBd4JsVs6a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "et5NhWn6VtO5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oDwRbdxTrSAu",
    "HYqQUEi-K-hU"
   ],
   "name": "homework-practice-08-random-features-ZhumataevZhantu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
